{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating images with MX-Font model from a reference style\n",
    "In this example we'll generate images with trained MX-Font model from a reference style.\n",
    "If you want to generate multiple styles, please check using `eval.py` instead of using this example file (because it is much simpler to load the referece styles)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Loading packages\n",
    "* First, load the packages used in this code.\n",
    "* All of the packages are avilable in `pip`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "from sconf import Config\n",
    "from torchvision import transforms\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import math\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* These modules are defined in this repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import models\n",
    "from datasets import read_font, render\n",
    "from utils import save_tensor_to_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Define Inference Handler Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InferenceHandler:\n",
    "    \n",
    "    def __init__(self, weight_path):\n",
    "        self.weight_path = weight_path\n",
    "\n",
    "    def build_model(self):\n",
    "        '''\n",
    "        Build and load the trained model.\n",
    "        '''\n",
    "        cfg = Config(\"cfgs/eval.yaml\", default=\"cfgs/defaults.yaml\")\n",
    "        self.transform = transforms.Compose(\n",
    "            [transforms.Resize((128, 128)), transforms.ToTensor(), transforms.Normalize([0.5], [0.5])]\n",
    "        )\n",
    "        self.decomposition = json.load(open(\"data/chn_decomposition.json\"))\n",
    "\n",
    "        g_kwargs = cfg.get('g_args', {})\n",
    "        self.gen = models.Generator(1, cfg.C, 1, **g_kwargs).cuda().eval()\n",
    "        weight = torch.load(self.weight_path)\n",
    "        if \"generator_ema\" in weight:\n",
    "            weight = weight[\"generator_ema\"]\n",
    "        self.gen.load_state_dict(weight)\n",
    "\n",
    "    def load_reference_images(self, data_path, exp_path):\n",
    "        '''\n",
    "        Load reference images\n",
    "        '''\n",
    "        self.data_path = data_path\n",
    "        self.exp_path =  exp_path\n",
    "\n",
    "        # Get a list of image files in the 'data/' folder\n",
    "        image_files = os.listdir(f'{self.data_path}')\n",
    "\n",
    "        print(image_files)\n",
    "\n",
    "        # Image Preprocessing: Loop through each image file\n",
    "        for image_file in image_files:\n",
    "            if image_file.endswith(('.jpg', '.png', '.jpeg')):  # Only process image files\n",
    "                # Load the image\n",
    "                image_path = os.path.join(self.data_path, image_file)\n",
    "                image = cv2.imread(image_path)\n",
    "\n",
    "                # Convert to grayscale\n",
    "                grayscale_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "                # Denoise the Image\n",
    "                denoised_image = cv2.fastNlMeansDenoising(grayscale_image, None, h=10, templateWindowSize=7, searchWindowSize=21)\n",
    "\n",
    "                # Create save directory\n",
    "                self.raw_imgs_path = f'{self.exp_path}/raw_imgs'\n",
    "                self.ref_imgs_path = f'{self.exp_path}/ref_imgs'\n",
    "                if not os.path.exists(self.raw_imgs_path): os.makedirs(self.raw_imgs_path)\n",
    "                if not os.path.exists(self.ref_imgs_path): os.makedirs(self.ref_imgs_path)\n",
    "\n",
    "                # Save the grayscale image in the 'result' folder\n",
    "                raw_img = os.path.join(self.raw_imgs_path, image_file)\n",
    "                ref_img = os.path.join(self.ref_imgs_path, image_file)\n",
    "                cv2.imwrite(raw_img, image)\n",
    "                cv2.imwrite(ref_img, denoised_image)\n",
    "\n",
    "                print(f'Converted {image_file} and saved as {ref_img}')\n",
    "\n",
    "        print(f'Done!!')\n",
    "\n",
    "    def extract_style_factor(self):\n",
    "        '''\n",
    "        * `ref_path`: \n",
    "            * The path of reference font or images.\n",
    "            * If you are using a ttf file, set this to the location of the ttf file.\n",
    "            * If you want to use rendered images, set this to the path to the directory which contains the reference images.\n",
    "        * `extension`:\n",
    "            * If you are using image files, set this to their extension(png, jpg, etc..). \n",
    "            * This will be ignored if `use_ttf` is True.\n",
    "        * `batch_size`:\n",
    "            * The number of images inferred at once.\n",
    "        '''\n",
    "        ref_path = self.ref_imgs_path  # Path to the reference images\n",
    "        extension = \"png\"  # Extension of the reference images\n",
    "        batch_size = 3  # The batch size\n",
    "\n",
    "        ref_paths = Path(ref_path).glob(f\"*.{extension}\")\n",
    "        ref_imgs = torch.stack([self.transform(Image.open(str(p))) for p in ref_paths]).cuda()\n",
    "        ref_batches = torch.split(ref_imgs, batch_size)\n",
    "\n",
    "        self.style_facts = {}\n",
    "\n",
    "        for batch in ref_batches:\n",
    "            style_fact = self.gen.factorize(self.gen.encode(batch), 0)\n",
    "            for k in style_fact:\n",
    "                self.style_facts.setdefault(k, []).append(style_fact[k])\n",
    "                \n",
    "        self.style_facts = {k: torch.cat(v).mean(0, keepdim=True) for k, v in self.style_facts.items()}\n",
    "\n",
    "    def generate_infer_imgs(self, gen_chars):\n",
    "        save_dir = Path(f\"{self.exp_path}/infer_imgs\")  # Directory where you want to save generated images\n",
    "        source_path = \"data/ttfs/source/chn_source.ttf\"  # Path to the font file to render the source images\n",
    "\n",
    "        save_dir.mkdir(parents=True, exist_ok=True)\n",
    "        source_font = read_font(source_path)\n",
    "\n",
    "        self.gen_img_list = []\n",
    "        for char in gen_chars:\n",
    "            source_img = self.transform(render(source_font, char)).unsqueeze(0).cuda()\n",
    "            char_facts = self.gen.factorize(self.gen.encode(source_img), 1)\n",
    "            \n",
    "            gen_feats = self.gen.defactorize([self.style_facts, char_facts])\n",
    "            out = self.gen.decode(gen_feats).detach().cpu()[0]\n",
    "\n",
    "            path = save_dir / f\"{char}.png\"\n",
    "            self.gen_img_list.append(path)\n",
    "            save_tensor_to_image(out, path)\n",
    "        \n",
    "        return self.gen_img_list\n",
    "\n",
    "    def show_inference_imgs(self):\n",
    "        images = []\n",
    "\n",
    "        for filename in self.gen_img_list:\n",
    "            img = cv2.imread(str(filename)) \n",
    "            if img is not None:\n",
    "                images.append(img)\n",
    "\n",
    "        plt.figure(figsize=(20,10))\n",
    "        columns = 5\n",
    "        for i, image in enumerate(images):\n",
    "            plt.subplot(math.ceil(len(images) / columns + 1), columns, i + 1)\n",
    "            plt.imshow(image)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Demonstration of the inference results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization\n",
    "weight_path = \"generator.pth\"  # path to weight to infer\n",
    "ih = InferenceHandler(weight_path)\n",
    "ih.build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment1\n",
    "data_path = \"data/images/lanting/4shot_01\"   # Path to the raw images\n",
    "exp_path  = \"exp/test1\"                     # Path to the experiment folder\n",
    "gen_chars = '床前明月光疑是地上霜举头望明月低头思故乡'\n",
    "ih.load_reference_images(data_path, exp_path)\n",
    "ih.extract_style_factor()\n",
    "ih.generate_infer_imgs(gen_chars)\n",
    "ih.show_inference_imgs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment2\n",
    "data_path = \"data/images/lanting/8shot_01\"   # Path to the raw images\n",
    "exp_path  = \"exp/test2\"                     # Path to the experiment folder\n",
    "gen_chars = '床前明月光疑是地上霜举头望明月低头思故乡'\n",
    "ih.load_reference_images(data_path, exp_path)\n",
    "ih.extract_style_factor()\n",
    "ih.generate_infer_imgs(gen_chars)\n",
    "ih.show_inference_imgs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment3\n",
    "data_path = \"data/images/lanting/8shot_02_bw\"   # Path to the raw images\n",
    "exp_path  = \"exp/test3\"                     # Path to the experiment folder\n",
    "gen_chars = '床前明月光疑是地上霜举头望明月低头思故乡'\n",
    "ih.load_reference_images(data_path, exp_path)\n",
    "ih.extract_style_factor()\n",
    "ih.generate_infer_imgs(gen_chars)\n",
    "ih.show_inference_imgs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment4\n",
    "data_path = \"data/images/lanting/8shot_03\"   # Path to the raw images\n",
    "exp_path  = \"exp/test4\"                     # Path to the experiment folder\n",
    "gen_chars = '床前明月光疑是地上霜举头望明月低头思故乡'\n",
    "ih.load_reference_images(data_path, exp_path)\n",
    "ih.extract_style_factor()\n",
    "ih.generate_infer_imgs(gen_chars)\n",
    "ih.show_inference_imgs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment5\n",
    "data_path = \"data/images/lanting/8shot_yf_01\"   # Path to the raw images\n",
    "exp_path  = \"exp/test5\"                     # Path to the experiment folder\n",
    "gen_chars = '床前明月光疑是地上霜举头望明月低头思故乡'\n",
    "ih.load_reference_images(data_path, exp_path)\n",
    "ih.extract_style_factor()\n",
    "ih.generate_infer_imgs(gen_chars)\n",
    "ih.show_inference_imgs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment6\n",
    "data_path = \"data/images/lanting/8shot_yf_01_rename\"   # Path to the raw images\n",
    "exp_path  = \"exp/test6\"                     # Path to the experiment folder\n",
    "gen_chars = '床前明月光疑是地上霜举头望明月低头思故乡'\n",
    "ih.load_reference_images(data_path, exp_path)\n",
    "ih.extract_style_factor()\n",
    "ih.generate_infer_imgs(gen_chars)\n",
    "ih.show_inference_imgs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment7\n",
    "data_path = \"data/images/lanting/8shot_yf_01_rename\"   # Path to the raw images\n",
    "exp_path  = \"exp/test7\"                     # Path to the experiment folder\n",
    "gen_chars = '吳永鋒'\n",
    "ih.load_reference_images(data_path, exp_path)\n",
    "ih.extract_style_factor()\n",
    "ih.generate_infer_imgs(gen_chars)\n",
    "ih.show_inference_imgs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment8\n",
    "data_path = \"data/images/lanting/8shot_yf_02\"   # Path to the raw images\n",
    "exp_path  = \"exp/test8\"                     # Path to the experiment folder\n",
    "gen_chars = '吳永鋒'\n",
    "ih.load_reference_images(data_path, exp_path)\n",
    "ih.extract_style_factor()\n",
    "ih.generate_infer_imgs(gen_chars)\n",
    "ih.show_inference_imgs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment9\n",
    "data_path = \"data/images/lanting/203shot\"   # Path to the raw images\n",
    "exp_path  = \"exp/test9\"                     # Path to the experiment folder\n",
    "gen_chars = '吳永鋒'\n",
    "ih.load_reference_images(data_path, exp_path)\n",
    "ih.extract_style_factor()\n",
    "ih.generate_infer_imgs(gen_chars)\n",
    "ih.show_inference_imgs()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
